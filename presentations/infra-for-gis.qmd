---
title: "GIS Infrastructure for Global Health & HIV-AIDS Programs"
date: "2023-10-18"
author: 
  - name: Baboyma Kagniniwa
    email: bkagniniwa@usaid.gov
  - name: Tim Essam
    email: tessam@usaid.gov
format: 
  revealjs:
    slide-number: c/t
    width: 1600
    height: 900
    logo: "https://usaid-oha-si.github.io/assets/img/si_logo_white.png"
    css: ["theme/theme.css"]
    theme: simple
    echo: true
    rtl: false
    incremental: true
    preview-links: auto
editor: visual
editor_options:
  chunk_output_type: inline
project:
    execute-dir: file
---

## Office of HIV/AIDS

Implement the U.S. President's Emergency Plan for AIDS Relief (PEPFAR)

![](https://www.state.gov/wp-content/uploads/2023/01/PEPFAR-20-Logo-Social-Tagged.jpg)

## About Us

The **Strategic Information Branch** **([GH/OHA/SIEI/SI](https://sites.google.com/a/usaid.gov/gh-oha/home/oha-divisions-branches/-strategic-information-evaluation-informatics-division/strategic-information-branch))** provides technical expertise to support and promote data-informed decision making, through program monitoring, reporting and analysis in order to target resources appropriately to achieve HIV epidemic control.

-   Support HQ and missions by building capacity for program monitoring and surveillance to improve HIV/AIDS programs and to provide accountability, oversight and management of programs and partners.

-   Focus on strengthening PEPFAR and USAID program data for use in inter-agency and intra-agency analyses.

-   [TL/DR: SI Branch is the data science hub of OHA]{style="color:#c43d4d; font-weight: bold;"}

# [Guiding Principles]{style="color:white;"} {#sec-guiding-principles background-image="https://unsplash.com/photos/CJBCaMkLP_U/download?ixid"}

## Organized around shared responsibility and accountability

-   Analyses are **well-documented, testable, reproducible**, and **open** to the office

-   Code pushed to github repositories are following **SI best practices**

-   Leverage **SI infrastructure** (R packages / OHA Style Guide / Tableau Prep Flows)

-   Continuous **integration** and **improvement** / **open feedback loops** (GitHub issues, after action reviews, etc.)

## Why this works

-   **Predictable** data structure, storage, and refresh schedule

-   Critical mass of **analysts who code** (or are learning)

-   **Space** for skill development and continuous learning

-   Support from **management**

# [Pre-COVID]{style="color:white;"} {#sec-pre-covid background-image="https://unsplash.com/photos/d1eaoAabeXs/download?ixid"}

## A Small But Mighty Team

1 GIS specialist for HQ & Country Support (50+ operating units)

- Requests for maps and other geospatial analysis were handle by **ONE** staff

- **ESRI ArcGIS** / **QGIS** were the only tools with limited number of licenses

- **1 MXD file** for a limited number of outputs & clicking is the way out of these updates

- Updating **recurring products** still meant clicking 1+

- The barrier to entry was high

- **The GIS Specialist** is way too busy to get into other lines of work

## COVID & WFH

OHA hired more **SI Advisers**, **Data Analysts**, and **Data Scientists** in response to an increase work load and number of request for country support.

- The office gain additional R users

- The front office is starting to push for more advanced geospatial analytics

- Hard to find COVID Data for PEPFAR Countries

- Humanitarian Exchange Website is now hosting some COVID Data - with frequent update

- R / RStudio is starting to compete with ESRI/ArcGIS, QGIS and Tableau

- SI Branch is also starting to figure out how to build of each others work

- **COVID Utilities** Package is born (inspired by ICPI Utilities)


# [Post-COVID]{style="color:white;"} {#sec-post-covid background-image="https://unsplash.com/photos/j2c7yf223Mk/download?ixid"}

## Digging a **PIT OF SUCCESS** for your organization

How does 1 GIS Specialist or a small group of analysts respond to a map requests from OHA and other 50+ HIV-AIDS Country programs during COP?

- You start by getting lost in your own home directory 

- ESRI ArcGIS, QGIS and Tableau are good but you are still standing still

- Scripting / Programming languages (R, Python, Go, ...) 

- Motivating others to run with you will pay off

- Embracing documentation, collaboration and reproducibility

- Continue to learn, teach and share

- You will probably get more work but eventually hand over the keys to mapping ...


## Open Source vs M/CIO 

M/CIO crack down on **Open Source Tools** due to the **Zero-trust policy** is threatening our Infrastructure

- Getting a new GFE is becoming scary ... 

- QGIS, R, RStudio, Git, Github are no longer approved for GFEs

- OHA, with the help of other R/RStudio users in the agency, has managed to get an exception

- We are now pushing for another exception for Git, if not Git + Github

- Tableau is also under scrutiny ... Will VDI Protect us better?

# [Tools and Capacity Building]{style="color:white;"} {#tools background-image="https://unsplash.com/photos/s8OO2-t-HmQ/download?ixid=MnwxMjA3fDB8MXxzZWFyY2h8Nnx8dG9vbHN8ZW58MHx8fHwxNjgxODIxNjY1&force=true&w=1920"}

## OHA Style Guide

[Style guide](https://issuu.com/achafetz/docs/oha_styleguide) serves as a tool to define and enhance brand cohesion. Where possible, we preset defaults (font, color, titles, captions) to save colleagues time and cognitive load.

[![](https://user-images.githubusercontent.com/5873344/232764503-ff2c980d-8de1-4572-993d-d111e43b54e9.png){fig-align="left"}](https://issuu.com/achafetz/docs/oha_styleguide)

## Core Software

::: columns
::: {.column width="50%"}
![](https://d33wubrfki0l68.cloudfront.net/1ac3f0e3753f18c7e2a8893957d1841fba1e3d08/48a33/wp-content/uploads/2018/10/rstudio-logo-flat.png){fig-align="center" width="500"}

![](https://dev3lop.com/wp-content/uploads/2017/04/tableau-logo-tableau-software.jpg){fig-align="center" width="500"}

![](https://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Microsoft_Office_Excel_(2019%E2%80%93present).svg/2203px-Microsoft_Office_Excel_(2019%E2%80%93present).svg.png){fig-align="center" width="189"}
:::

::: {.column width="50%"}
![](https://cdn.freebiesupply.com/logos/thumbs/2x/git-logo.png){fig-align="center" width="235"}

![](https://1000logos.net/wp-content/uploads/2021/05/GitHub-logo.png){fig-align="center" width="313"}

![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Adobe_Illustrator_CC_icon.svg/2101px-Adobe_Illustrator_CC_icon.svg.png){fig-align="center" width="181"}
:::
:::

## R + RStudio

R + Rstudio is our primary analytic tool. Most of the SI infrastructure is based on `tidyverse` principles and workflows.

::: columns
::: {.column width="60%"}
::: {layout-nrow="3"}
[![](https://github.com/USAID-OHA-SI/glitr/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/glitr/) [![](https://github.com/USAID-OHA-SI/glamr/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/glamr) [![](https://github.com/USAID-OHA-SI/gophr/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/gophr) [![](https://github.com/USAID-OHA-SI/gisr/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/gisr/)

[![](https://github.com/USAID-OHA-SI/gagglr/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/gagglr) [![](https://github.com/USAID-OHA-SI/grabr/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/grabr) [![](https://github.com/USAID-OHA-SI/Wavelength/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/Wavelength) [![](https://github.com/USAID-OHA-SI/tameDP/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/tameDP)

[![](https://github.com/USAID-OHA-SI/mindthegap/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/mindthegap) [![](https://github.com/USAID-OHA-SI/COVIDutilities/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/COVIDutilities) [![](https://github.com/USAID-OHA-SI/selfdestructin5/raw/main/man/figures/logo.png){width="175"}](https://usaid-oha-si.github.io/selfdestructin5/) [![](https://github.com/USAID-OHA-SI/coRps/raw/main/figures/logo.png){width="175"}](https://github.com/USAID-OHA-SI/coRps)
:::
:::
::: {.column width="40%"}
[![](https://github.com/USAID-OHA-SI/gisr/raw/main/man/figures/logo.png){width="600"}](https://usaid-oha-si.github.io/gisr/)
:::
:::


## Git + Github

Use git locally for version control and Github to store packages and analytic code online. This allows for remote collaboration and serves as a default knowledge management platform.

*No data are stored on GitHub -- only code.*

![](https://user-images.githubusercontent.com/5873344/232575267-f395d8ae-859e-4443-a563-b5c4fe81d61e.PNG)

## Capacity Building

Make a personal commitment to continue to learn, teach, mentor and share your work with others. Blogs, brown bags, learning collaboratively, training sessions are also good options.

Always make time to help others reproduce what you've done and/or shared.
[![](https://usaid-oha-si.github.io/assets/img/posts/20220606-rbbs-rbbs-mapping_with_r-20220606_rbbs_11-mapping.png)](https://usaid-oha-si.github.io/learn/)

# [DEMOS]{style="color:white;"} {#examples background-image="https://unsplash.com/photos/AFB6S2kibuk/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8Nnx8bWFwc3xlbnwwfHx8fDE2OTcxNjUzODl8MA&force=true&w=1920"}

## Geospatial Datasets

[DATIM](https://datim.org) is the official data management system for all PEPFAR Programs across countries. Geospatial datasets are also part of this system.


- Program data (**Where**, What, Who, What): 
  
  - Finance and Expenditure Reports (ER)
  - Monitoring Evaluation and Reporting (**MER**)
  - Human Resources for Health (HRH)
  - Site Improvement Through Monitoring System (SIMS)
  - More ...

- Geospatial: 

  - Facilities
  - Administrative boundaries
  
## Identify and Extract Geodata

PEPFAR location (where) data are organized into organisational hierarchies (orgunit) unique identifiers (orgunit uid). The global shapefile shared has only 1 attribue: `uid` for `orgunit_uid`.

Let's find the file. We need to load some libraries and setup our reference directories.

```{r}
#| label: libs
#| echo: true

# Libraries

# Posit data munging and viz libraies
library(tidyverse)
library(sf)
# OHA Custom Packages
library(glamr) # Utilities functions
library(grabr) # API Utilities
library(gisr)  # Mapping
library(glitr) # OHA Style guide

# Directories
dir_vec <- si_path(type = "path_vector")
dir_ras <- si_path(type = "path_raster")
dir_mer <- si_path(type = "path_msd")

# Output path
dir_vec

```

## Identify and Extract Geodata 

Let's locate the file. 

```{r, `code-line-numbers` = "13-17"}
#| label: setup
#| echo: true
#| output: false

# Files

getwd()

list.files("..")

list.files(file.path("..", dir_vec))

list.files(path = file.path("..", dir_vec), 
           pattern = "VcPepfarPolygons.shp", 
           recursive = TRUE)

pepfar_shp <- return_latest(
  folderpath = file.path("..", dir_vec), 
  pattern = "VcPepfarPolygons.shp", 
  recursive = TRUE
)

```

```{r}
#| label: shp-data
#| echo: false
#| output: true
pepfar_shp
```

## Identify and Extract Geodata 

What is inside this shapefile? 

```{r, `code-line-numbers` = "13-17"}
#| label: shp-str
#| echo: true
#| output: false

# Global shapefile
spdf <- read_sf(pepfar_shp)

# glimpse(spdf)

# Rows: 7,429
# Columns: 2
# $ uid      <chr> "uXwFHXCPYgj", "Yhf4p9zEkYl", "P82LOpqd4Bx", "MTPoa0xZGqK", …
# $ geometry <MULTIPOLYGON [°]> MULTIPOLYGON (((13.39702 -8..., MULTIPOLYGON ((…

```

## Identify and Extract Geodata 

What's the content of this shapefile? 

This can be accomplished with base R or ggplot2

```{r}
#| label: shp-view-base
#| echo: true
#| output: false
#| eval: false

# Base ploting
plot(spdf)

# or

# ggplot plot
spdf %>% 
  ggplot() +
  geom_sf(fill = NA, lwd = .3, color = "#6c6463")
```

We just need 1 line with simplified output

```{r}
#| label: shp-view-ggplot
#| output: false
#| eval: false
# Custom plot based of ggplot + geom_sf
gview(spdf)
```

## Identify and Extract Geodata 

![](./infra-for-gis_files/figure-revealjs/shp-view-ggplot-1.png)

## Identify and Extract Geodata 

This looks like a global dataset. Can I extract data for 1 country? 

Let's find the country uid first and then extract the country boundary

```{r}
#| label: shp-cntry
#| echo: true
#| output: false
#| eval: true

# Param
cntry <- "Nigeria"

# extract country uid
cntry_uid <- get_ouuid(operatingunit = cntry,
                       username = datim_user(),
                       password = datim_pwd(),
                       baseurl = "https://datim.org/")

# filter out country boundary
cntry_shp <- spdf %>% filter(uid == cntry_uid)

```

Visualize the country boundary

```{r}
#| label: shp-cntry-view
#| eval: false

# View
gview(cntry_shp)
```

## Identify and Extract Geodata 

![](./infra-for-gis_files/figure-revealjs/shp-cntry-view-1.png)

## Identify and Extract Geodata 

Let's now extract a lower orgunit level (administrative unit: state / PSNU)

```{r}
#| label: shp-psnu
#| echo: true
#| output: false
#| eval: true

# extract orgunit levels

df_lvls <- get_levels(username = datim_user(), password = datim_pwd())

df_lvls <- df_lvls %>% 
  pivot_longer(cols = where(is.numeric),
               names_to = "orgunit_label", values_to = "orgunit_level") %>% 
  filter(countryname == cntry)

lvl_psnu <- get_ouorglevel(operatingunit = cntry, org_type = "prioritization",
                           username = datim_user(), password = datim_pwd())

orgs_psnu <- get_ouorguids(ouuid = cntry_uid, level = lvl_psnu,
                           username = datim_user(), password = datim_pwd())

# filter out country boundary
psnu_shp <- spdf %>% filter(uid %in% orgs_psnu)

```

Visualize the state boundaries

```{r}
#| label: shp-psnu-view
#| eval: false
gview(psnu_shp)
```

## Identify and Extract Geodata 

![](./infra-for-gis_files/figure-revealjs/shp-psnu-view-1.png)

## Basemaps

How can we use these administrative boundaries data?

Let's make a basemap using some terrain datasets - raster 

```{r}
#| label: ras-global
#| eval: true
#| echo: true
#| output: false
#| warning: false
#| error: false

# Terrain data
terr <- get_raster(path = file.path("..", dir_ras))

# class      : RasterLayer 
# dimensions : 8100, 16200, 131220000  (nrow, ncol, ncell)
# resolution : 0.02222222, 0.02222222  (x, y)
# extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
# crs        : +proj=longlat +datum=WGS84 +no_defs 
# source     : SR_LR.tif 
# names      : SR_LR 
```

## Basemaps

Generate a basemap using administrative boundaries from naturalearth

```{r}
#| label: ras-basemap-1
#| echo: true
#| output: false
#| eval: true
#| warning: false

# Basemap - this is built on top of Naturalearth Data
bmap <- terrain_map(countries = cntry, terr = terr, mask = TRUE)
```

Visualize the basemap

```{r}
#| label: ras-basemap-view-1
#| echo: true
#| eval: true
#| warning: false
bmap
```

## Basemaps

Generate a basemap with specific datasets

```{r}
#| label: ras-basemap-2
#| echo: true
#| output: false
#| eval: true
#| warning: false

# Basemap
bmap <- terrain_map(countries = cntry_shp,
                    adm0 = cntry_shp, adm1 = psnu_shp, 
                    terr = terr, mask = TRUE)
```

Visualize the basemap

```{r}
#| label: ras-basemap-view-2
#| echo: true
#| eval: true
#| warning: false
bmap
```

## Basemaps

Generate a basemap with labels

```{r}
#| label: ras-basemap-3
#| echo: true
#| output: false
#| eval: true
#| warning: false

# Get attributes tables
df_psnu <- datim_orgunits(cntry = cntry,
                          username = datim_user(),
                          password = datim_pwd()) %>% 
  filter(orgunit_level == lvl_psnu) %>% 
  rename_with(.cols = ends_with("_internal_id"),
              .fn = ~str_replace(., "internal_id", "uid"))

psnu_shp <- psnu_shp %>% 
  left_join(df_psnu, by = c("uid" = "orgunit_uid")) %>% 
  filter(!is.na(orgunit_name))

# Basemap
bmap <- terrain_map(countries = cntry_shp,
                    adm0 = cntry_shp, adm1 = psnu_shp, 
                    terr = terr, mask = TRUE) 

bmap <- bmap +
  geom_sf_text(data = psnu_shp, 
               aes(label = orgunit_name),
               size = 3, color = usaid_black)
```

## Basemaps

Visualize the basemap

```{r}
#| label: ras-basemap-output
#| echo: true
#| eval: true
#| warning: false
#| 
bmap
```

## Basemaps

Let's summarize what we've done so far

```{r}
#| label: ras-basemap-summary-global
#| class-output: hscroll
#| echo: true
#| output: false
#| eval: true
#| logging: 
#| warning: false

# Global shapefile
spdf <- read_sf(pepfar_shp)

# Terrain data
terr <- get_raster(path = file.path("..", dir_ras))

# Global Orgunit levels
df_lvls <- get_levels(username = datim_user(), password = datim_pwd()) %>% 
  pivot_longer(cols = where(is.numeric), names_to = "orgunit_label", values_to = "orgunit_level")
```

```{r}
#| label: ras-basemap-summary-cntry
#| class-output: hscroll
#| echo: true
#| output: false
#| eval: true
#| logging: 
#| warning: false

# Country specific parameters

# Country
cntry <- "Nigeria"

# extract country uid
cntry_uid <- get_ouuid(operatingunit = cntry,
                       username = datim_user(),
                       password = datim_pwd(),
                       baseurl = "https://datim.org/")

df_orgs <- datim_orgunits(cntry = cntry, username = datim_user(), password = datim_pwd()) %>% 
  rename_with(.cols = ends_with("_internal_id"),
              .fn = ~str_replace(., "internal_id", "uid"))

lvl_psnu <- df_lvls %>% 
  filter(countryname == cntry, orgunit_label == "prioritization") %>% 
  pull(orgunit_level)

# Get attributes tables
df_psnu <- df_orgs %>% 
  filter(orgunit_level == lvl_psnu) 

# filter out country boundary
cntry_shp <- spdf %>% filter(uid == cntry_uid)
  
# filter out psn
psnu_shp <- df_orgs %>% 
  filter(orgunit_level == lvl_psnu)  %>% 
  left_join(spdf, ., by = c("uid" = "orgunit_uid")) %>% 
  filter(!is.na(orgunit_name))

# Basemap
bmap <- terrain_map(countries = cntry_shp,
                    adm0 = cntry_shp, adm1 = psnu_shp, 
                    terr = terr, mask = TRUE) 

bmap <- bmap +
  geom_sf_text(data = psnu_shp, 
               aes(label = orgunit_name),
               size = 3, color = usaid_black)
```

## Basemaps

Visualize the basemap

```{r}
#| label: ras-basemap-summary-cntry
#| class-output: hscroll
#| echo: true
#| output: true
#| eval: true
#| warning: false

bmap
```

## Basemaps

Let's produce these basemap for multiple countries

```{r}

#| label: ras-basemap-summary-cntry
#| class-output: hscroll
#| echo: true
#| output: false
#| eval: true
#| warning: false

# Distinct countries list
countries <- df_lvls %>% 
  filter(str_detect(operatingunit, "Region$", negate = TRUE)) %>% 
  distinct(countryname) %>% 
  pull()

countries %>% 
  sample(size = 5, replace = FALSE) %>% 
  walk(function(.cntry){
    
    print(.cntry)
    
    # extract country uid
    .cntry_uid <- get_ouuid(operatingunit = .cntry,
                           username = datim_user(),
                           password = datim_pwd(),
                           baseurl = "https://datim.org/")
    
    .df_orgs <- datim_orgunits(cntry = .cntry, username = datim_user(), password = datim_pwd()) %>% 
      rename_with(.cols = ends_with("_internal_id"),
                  .fn = ~str_replace(., "internal_id", "uid"))
    
    .lvl_psnu <- df_lvls %>% 
      filter(countryname == .cntry, orgunit_label == "prioritization") %>% 
      pull(orgunit_level)
    
    # Get attributes tables
    .df_psnu <- .df_orgs %>% filter(orgunit_level == .lvl_psnu) 
    
    # filter out country boundary
    .cntry_shp <- spdf %>% filter(uid == .cntry_uid)
      
    # filter out psnu
    .psnu_shp <- .df_orgs %>% 
      filter(orgunit_level == .lvl_psnu)  %>% 
      left_join(spdf, ., by = c("uid" = "orgunit_uid")) %>% 
      filter(!is.na(orgunit_name))
    
    # Basemap
    .bmap <- terrain_map(countries = .cntry_shp,
                        adm0 = .cntry_shp, adm1 = .psnu_shp, 
                        terr = terr, mask = TRUE) 
    
    # .bmap <- .bmap +
    #   geom_sf_text(data = .psnu_shp, 
    #                aes(label = orgunit_name),
    #                size = 3, color = usaid_black)
    
    print(.bmap)
  })
  
```